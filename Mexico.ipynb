{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import models, optimizers\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from datetime import datetime as dt\n",
    "from sklearn.model_selection import KFold\n",
    "import import_ipynb\n",
    "from Model_dev import compress_to_2d, get_model, LSTM_model, Attention, C_LSTM, data_handling, model_development, rmse, draw_graph\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = 'Mexico'\n",
    "datadir = os.path.join(os.getcwd(), \"Data\")\n",
    "modeldir = os.path.join(os.getcwd(), \"Models\")\n",
    "logdir = os.path.join(os.getcwd(), \"Log\")\n",
    "filename = \"Full_{}.csv\".format(country)\n",
    "filepath = os.path.join(datadir, filename)\n",
    "social_media = ['like_index','retweet_index']\n",
    "covid_cases = ['ConfirmedCases', 'ConfirmedDeaths', 'Daily_cases']\n",
    "general_info = ['CountryCode_x', 'CountryName_x', 'Jurisdiction', 'Date']\n",
    "num_variable = ['E3_Fiscal measures', 'E4_International support', 'H5_Investment in vaccines', 'H4_Emergency investment in healthcare']\n",
    "required_days = 14\n",
    "pred_days = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(modeldir):\n",
    "    os.mkdir(modeldir)\n",
    "if not os.path.isdir(logdir):\n",
    "    os.mkdir(logdir)\n",
    "if not os.path.isdir(datadir):\n",
    "    os.mkdir(datadir)\n",
    "if not os.path.isdir(os.path.join(logdir, country)):\n",
    "    os.mkdir(os.path.join(logdir, country))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filepath, index_col=0)\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "policy = []\n",
    "columns = df.columns\n",
    "for column in columns:\n",
    "    if not any(column in _list for _list in [social_media, general_info, covid_cases]):\n",
    "        policy.append(column)\n",
    "categorical_variable = list(set(policy) - set(num_variable))\n",
    "df[categorical_variable] = df[categorical_variable].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = policy\n",
    "x_train, x_test, y_train, y_test = data_handling(df, features, required_days, pred_days)\n",
    "model_development(x_train, x_test, y_train, y_test, \"P\", country, modeldir, logdir, required_days, pred_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = policy + covid_cases\n",
    "x_train, x_test, y_train, y_test = data_handling(df, features, required_days, pred_days)\n",
    "model_development(x_train, x_test, y_train, y_test, \"PC\", country, modeldir, logdir, required_days, pred_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = policy + covid_cases + social_media\n",
    "x_train, x_test, y_train, y_test = data_handling(df, features, required_days, pred_days)\n",
    "model_development(x_train, x_test, y_train, y_test, \"PCS\", country, modeldir, logdir, required_days, pred_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Best model for the country\n",
    "log_file = os.path.join(logdir,\"Models.csv\")\n",
    "best_result = get_model(log_file, country)\n",
    "\n",
    "features_used = best_result['Features'].values[0]\n",
    "algo = best_result['Algorithm'].values[0]\n",
    "best_model_filepath = best_result['Model_path'].values[0]\n",
    "best_model = models.load_model(best_model_filepath, custom_objects={'rmse':rmse})\n",
    "config = best_model.get_config()\n",
    "\n",
    "if features_used == \"P\":\n",
    "    features = policy\n",
    "elif features_used == \"PC\":\n",
    "    features = policy + covid_cases\n",
    "else:\n",
    "    features = policy + covid_cases + social_media\n",
    "\n",
    "x_train, x_test, y_train, y_test = data_handling(df, features, required_days, pred_days)\n",
    "y_pred_train = compress_to_2d(best_model.predict(x_train))\n",
    "y_pred_test = compress_to_2d(best_model.predict(x_test))\n",
    "y_true_train = compress_to_2d(y_train)\n",
    "y_true_test = compress_to_2d(y_test)\n",
    "\n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "loss = mse(y_true_train, y_pred_train).numpy()\n",
    "val_loss = mse(y_true_test, y_pred_test).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=100, mode='min')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=10, factor=0.4, min=0.00001)\n",
    "opt = optimizers.Adam(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Feature importance for the country\n",
    "result = {}\n",
    "\n",
    "for i in range(len(policy)):\n",
    "    \n",
    "    target = policy[i]\n",
    "    x_train, x_test, y_train, y_test = data_handling(df, features, required_days, pred_days, swap_col=target)\n",
    "    \n",
    "    exp_train = compress_to_2d(best_model.predict(x_train))\n",
    "    exp_test = compress_to_2d(best_model.predict(x_test))\n",
    "    \n",
    "    draw_graph(exp_train, exp_test, y_true_train, y_true_test, required_days, pred_days, country, features_used, x_train, algo)\n",
    "    \n",
    "    _loss = mse(y_true_train, exp_train).numpy()\n",
    "    _val_loss = mse(y_true_test, exp_test).numpy()\n",
    "    \n",
    "    print(\"######\", target, \"#####\")\n",
    "    print(\"Changes in loss: {}\".format(_loss-loss))\n",
    "    print(\"Changes in Validation loss: {}\".format(_val_loss-val_loss))\n",
    "    \n",
    "    result[target] = [loss, val_loss, _loss, _val_loss, _loss-loss, _val_loss-val_loss, _loss/loss, _val_loss/val_loss]\n",
    "\n",
    "Changes = pd.DataFrame.from_dict(result, orient='index', columns=['Old loss', 'Old Validation loss', 'New Loss', 'New Validation Loss', 'Changes in loss', \n",
    "                                                                 'Changes in validation loss', 'Ratio of new-old loss', 'Ratio of new-old validation loss'])\n",
    "Changes.to_csv(os.path.join(logdir, \"{}/{}_feat_importance.csv\".format(country, country)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Feature importance for the country each month\n",
    "months = ['Jan', 'Feb', 'March', 'April', 'May', 'June', 'July', 'August', 'Sept']\n",
    "\n",
    "for i in range(len(months)):\n",
    "\n",
    "    tmp = df[pd.to_datetime(df.index, dayfirst=True) < dt(2021, i+2, 1)]\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = data_handling(tmp, features, required_days, pred_days, test_size=30)\n",
    "    y_pred_train = compress_to_2d(best_model.predict(x_train))\n",
    "    y_pred_test = compress_to_2d(best_model.predict(x_test))\n",
    "    y_true_train = compress_to_2d(y_train)\n",
    "    y_true_test = compress_to_2d(y_test)\n",
    "\n",
    "    mse = tf.keras.losses.MeanSquaredError()\n",
    "    loss = mse(y_true_train, y_pred_train).numpy()\n",
    "    val_loss = mse(y_true_test, y_pred_test).numpy()\n",
    "    \n",
    "    result2 = {}\n",
    "    \n",
    "    print(\"######\", months[i], \"#####\")\n",
    "\n",
    "    for j in range(len(policy)):\n",
    "        \n",
    "        target = policy[j]\n",
    "        xx_train, xx_test, yy_train, yy_test = data_handling(tmp, features, required_days, pred_days, swap_col=target, test_size=30)\n",
    "    \n",
    "        exp_train = compress_to_2d(best_model.predict(xx_train))\n",
    "        exp_test = compress_to_2d(best_model.predict(xx_test))\n",
    "    \n",
    "        draw_graph(exp_train, exp_test, y_true_train, y_true_test, required_days, pred_days, country, features_used, xx_train, algo)\n",
    "\n",
    "        _loss = mse(y_true_train, exp_train).numpy()\n",
    "        _val_loss = mse(y_true_test, exp_test).numpy()\n",
    "\n",
    "        print(\"######\", target, \"#####\")\n",
    "        print(\"Changes in loss: {}\".format(_loss-loss))\n",
    "        print(\"Changes in Validation loss: {}\".format(_val_loss-val_loss))\n",
    "\n",
    "        result2[target] = [loss, val_loss, _loss, _val_loss, _loss-loss, _val_loss-val_loss, _loss/loss, _val_loss/val_loss]\n",
    "\n",
    "    Changes = pd.DataFrame.from_dict(result2, orient='index', columns=['Old loss', 'Old Validation loss', 'New Loss', 'New Validation Loss', 'Changes in loss', \n",
    "                                                                 'Changes in validation loss', 'Ratio of new-old loss', 'Ratio of new-old validation loss'])\n",
    "    Changes.to_csv(os.path.join(logdir, \"{}/{}_feat_importance_{}.csv\".format(country, country, months[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance for the country\n",
    "result2 = {}\n",
    "\n",
    "for i in range(len(policy)):\n",
    "    \n",
    "    target = policy[i]\n",
    "    x_train, x_test, y_train, y_test = data_handling(df, features, required_days, pred_days, swap_col=target)\n",
    "        \n",
    "    if algo == 'Attention':\n",
    "        model = keras.Model.from_config(config)\n",
    "    else:\n",
    "        model = keras.Sequential.from_config(config)\n",
    "\n",
    "    model.compile(optimizer=opt, loss=rmse)\n",
    "    model.summary()\n",
    "    \n",
    "    kf = KFold()\n",
    "    for train_index, test_index in kf.split(x_train):\n",
    "        xx_train, xx_test = x_train[train_index], x_train[test_index]\n",
    "        yy_train, yy_test = y_train[train_index], y_train[test_index]\n",
    "        \n",
    "        history = model.fit(xx_train, yy_train, shuffle=True,\n",
    "                 validation_data=(xx_test, yy_test),\n",
    "                 epochs=1000,\n",
    "                 callbacks=[early_stopping, reduce_lr],\n",
    "                 verbose=0)\n",
    "    \n",
    "    exp_train = compress_to_2d(model.predict(x_train))\n",
    "    exp_test = compress_to_2d(model.predict(x_test))\n",
    "\n",
    "    _loss = mse(y_true_train, exp_train).numpy()\n",
    "    _val_loss = mse(y_true_test, exp_test).numpy()\n",
    "    \n",
    "    print(\"######\", target, \"#####\")\n",
    "    print(\"Changes in loss: {}\".format(_loss-loss))\n",
    "    print(\"Changes in Validation loss: {}\".format(_val_loss-val_loss))\n",
    "    \n",
    "    result2[target] = [loss, val_loss, _loss, _val_loss, _loss-loss, _val_loss-val_loss, _loss/loss, _val_loss/val_loss]\n",
    "\n",
    "Changes = pd.DataFrame.from_dict(result2, orient='index', columns=['Old loss', 'Old Validation loss', 'New Loss', 'New Validation Loss', 'Changes in loss', \n",
    "                                                                 'Changes in validation loss', 'Ratio of new-old loss', 'Ratio of new-old validation loss'])\n",
    "Changes.to_csv(os.path.join(logdir, \"{}_feat_importance.csv\".format(country)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
